<!DOCTYPE html>
<!-- saved from url=(0026)https://psh01087.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Required meta tags -->

    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title>Sunghyun Park</title>
    <style type="text/css">
    .center {
        text-align: center;
    }

    .lead {
        font-size: 0.95rem;
        text-align: left;
    }

    .subtitle {
        font-size: 1.7rem;
        text-align: left;
    }

    .title {
        font-size: 2.2rem;
        text-align: left;
    }

    .ttitle {
    font-size: 1.2rem;
    text-align: left;
    }
    </style>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script type="text/javascript" async="" src="./sources/analytics.js"></script><script async="" src="./sources/js"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-141257534-1');
    </script>
</head>

<body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
    <div class="container" style="margin-top:10px;">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <!-- Intro -->
                <div>
                    <div class="row">
                        <div class="col-sm-5">
                            <img src="./images/profile.jpg" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <header>
                                <h3 class="title">Sunghyun Park </h3>
                                <h3 class="ttitle">Ph.D. Student <br>
                                KAIST<br>
                                psh01087[at]kaist[dot]]ac[dot]kr</h3>
                                <div class="links">
                                    <a href="https://scholar.google.com/citations?user=dYJaOh8AAAAJ&hl=ko">[Google Scholar]</a>
				                    <a href="https://github.com/psh01087">[Github]</a>
                                    <a href="./sources/CV.pdf">[CV]</a>
                                </div>
                            </header>
                        </div>
                    </div>
                </div>
                <!-- About Me -->
                <hr>
                <div>
                    <h3 class="subtitle">About Me</h3>
                    <p class="lead">
                        I am a Ph.D. student at Korea Advanced Institute of Science and Technology (KAIST) advised by Professor <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
                    </p>
                </div>
                <!-- News -->
                <hr>
                <div>
                    <h3 class="subtitle">News</h3>
                    <p class="lead">
                        <span class="font-weight-bold">[Dec. 2023]</span> New Normal paper accepted to <a href="https://aaai.org/aaai-conference/">AAAI 2024</a>.</br>
                        <span class="font-weight-bold">[Nov. 2023]</span> I successfully defended my PhD thesis!</br>
                        <span class="font-weight-bold">[Jul. 2023]</span> Label Shift Adapter paper accepted to <a href="https://iccv2023.thecvf.com/">ICCV 2023</a>.</br>
                        <span class="font-weight-bold">[May. 2023]</span> Paint-by-Sketch paper accepted to <a href="https://ai4cc.net/">AI4CC CVPRW 2023</a>.</br>
                        <span class="font-weight-bold">[Oct. 2022]</span> I started internship at <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research">Qualcomm AI Research</a>.</br>
                        <span class="font-weight-bold">[Oct. 2022]</span> Best Paper Award, Korean Artificial Intelligence Association 2022 (AnimeCeleb).</br>
                        <span class="font-weight-bold">[Jul. 2022]</span> 3 papers accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.</br>
                        <!-- <span class="font-weight-bold">[Nov. 2021]</span> Qualcomm Innovation Fellowship Korea 2021 (Vid-ODE).</br> -->
                        <!-- <span class="font-weight-bold">[Nov. 2021]</span> Best Paper Award, Korean Artificial Intelligence Association 2021 (HairFIT).</br> -->
                        <!-- <span class="font-weight-bold">[Oct. 2021]</span> 3 papers accepted to <a href="http://www.bmvc2021.com/">BMVC 2021</a>.</br> -->
                        <!-- <span class="font-weight-bold">[May. 2021]</span> K-Hairstyle paper accepted to <a href="https://www.2021.ieeeicip.org/">ICIP 2021</a>.</br> -->
                        <!-- <span class="font-weight-bold">[Mar. 2021]</span> I started internship at AI Lab, <a href="https://www.kakaoenterprise.com/">Kakao Eneterprise</a>.</br> -->
                        <!-- <span class="font-weight-bold">[Feb. 2021]</span> VITON-HD paper accepted to <a href="https://cvpr2021.thecvf.com/">CVPR 2021</a>.</br> -->
                        <!-- <span class="font-weight-bold">[Dec. 2020]</span> Vid-ODE paper accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</br> -->
                    </p>
                </div>
                <!-- Publications -->
                <hr>
                <div>
                    <h3 class="subtitle">Publications</h3>
                    <!-- When Model Meets New Normals -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/new_normal.jpg" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection</span><br>
                                Dongmin Kim, <span class="font-weight-bold">Sunghyun Park</span>, and Jaegul Choo<br>
                                <i>AAAI Conference on Artificial Intelligence (AAAI), 2024, Vancouver, Accepted.</i><br>
                                <a href="">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Label Shift Adapter -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/label_shift_adapter.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</span><br>
                                <span class="font-weight-bold">Sunghyun Park</span>, Seunghan Yang, Jaegul Choo, and Sungrack Yun<br>
                                <i>International Conference on Computer Vision (ICCV), 2023, Paris, Accepted.</i><br>
                                <a href="">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Paint-by-Sketch -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/paint_by_sketch.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Reference-based Image Composition with Sketch via Structure-aware Diffusion Model</span><br>
                                Kangyeol Kim, <span class="font-weight-bold">Sunghyun Park</span>, Junsoo Lee, and Jaegul Choo<br>
                                <i>CVPR Workshop on AI for Content Creation, 2023.</i><br>
                                <a href="http://arxiv.org/abs/2304.09748">[Paper]</a>
                                <a href="https://github.com/kangyeolk/Paint-by-Sketch">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <!-- AnimeCeleb -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/animeceleb.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">AnimeCeleb: Large-Scale Animation CelebHeads Dataset for Head Reenactment</span><br>
                                Kangyeol Kim*, <span class="font-weight-bold">Sunghyun Park*</span>, Jaeseong Lee*, Sunghyo Chung, Junsoo Lee, and Jaegul Choo<br>
                                <i>European Conference on Computer Vision (ECCV), 2022, Tel Aviv, Accepted</i><br>
                                <i style="color:red;">Best Paper Award, Korean Artificial Intelligence Association 2022.</i><br>
                                <a href="https://arxiv.org/abs/2111.07640">[Paper]</a>
                                <a href="https://github.com/kangyeolk/AnimeCeleb">[Code & Dataset]</a>
                            </p>
                        </div>
                    </div>
                    <!-- HR-VITON -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/hr-viton.jpg" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">High-Resolution Virtual Try-On width Misalignment and Occlusion-Handled Conditions</span><br>
                                SangYun Lee*, Gyojung Gu*, <span class="font-weight-bold">Sunghyun Park</span>, Seunghwan Choi, and Jaegul Choo<br>
                                <i>European Conference on Computer Vision (ECCV), 2022, Tel Aviv, Accepted</i><br>
                                <a href="https://arxiv.org/abs/2206.14180">[Paper]</a>
                                <a href="https://github.com/sangyun884/HR-VITON">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Style Your Hair -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/style-hair.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Style Your Hair: Latent Optimization for Pose-Invariant Hairstyle Transfer via Local-Style-Aware Hair Alignment</span><br>
                                Chaeyeon Chung*, Taewoo Kim*, Yoonseo Kim*, <span class="font-weight-bold">Sunghyun Park</span>, Kangyeol Kim, and Jaegul Choo<br>
                                <i>European Conference on Computer Vision (ECCV), 2022, Tel Aviv, Accepted</i><br>
                                <a href="">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- HairFIT -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/hairfit.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">HairFIT: Pose-invariant Hairstyle Transfer via Flow-based Hair Alignment and Semantic-region-aware Inpainting</span><br>
                                Chaeyeon Chung*, Taewoo Kim*, Hyelin Nam*, Seunghwan Choi, Gyojung Gu, <span class="font-weight-bold">Sunghyun Park</span>, and Jaegul Choo<br>
                                <i>British Machine Vision Conference (BMVC), 2021, Virtual, Accepted as Oral Presentation.</i><br>
                                <i style="color:red;">Best Paper Award, Korean Artificial Intelligence Association 2021.</i><br>
                                <a href="https://arxiv.org/abs/2206.08585">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- MODE-GAN -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/mode-gan.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Continuous-Time Video Generation via Learning Motion Dynamics with Neural ODE</span><br>
                                Kangyeol Kim*, <span class="font-weight-bold">Sunghyun Park*</span>, Junsoo Lee, Joonseok Lee, Sookyung Kim, Jaegul Choo, and Edward Choi<br>
                                <i>British Machine Vision Conference (BMVC), 2021, Virtual, Accepted.</i><br>
                                <a href="https://arxiv.org/abs/2112.10960">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Missing Children -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/missing_children.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Improving Face Recognition with Large Age Gaps by Learning to Distinguish Children</span><br>
                                Jungsoo Lee*, Jooyeol Yun*, <span class="font-weight-bold">Sunghyun Park</span>, Yonggyu Kim, and Jaegul Choo<br>
                                <i>British Machine Vision Conference (BMVC), 2021, Virtual, Accepted.</i><br>
                                <a href="https://arxiv.org/abs/2110.11630">[Paper]</a>
                                <a href="https://github.com/leebebeto/Inter-Prototype">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <!-- K-Hairstyle -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/k-hairstyle.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">K-Hairstyle: A Large-scale Korean Hairstyle Dataset for Virtual Hair Editing and Hairstyle Classification</span><br>
                                Taewoo Kim*, Chaeyeon Chung*, <span class="font-weight-bold">Sunghyun Park*</span>, Gyojung Gu, Keonmin Nam, Wonzo Choe, Jaesung Lee and Jaegul Choo<br>
                                <i>IEEE International Conference on Image Processing (ICIP), 2021, Virtual, Accepted.</i><br>
                                <a href="https://arxiv.org/abs/2102.06288">[Paper]</a>
                                <a href="https://psh01087.github.io/K-Hairstyle/">[Project & Dataset]</a>
                                <a href="https://n.news.naver.com/article/469/0000618850?cds=news_my">[News]</a>
                            </p>
                        </div>
                    </div>
                    <!-- VITON-HD -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/viton-hd.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization</span><br>
                                Seunghwan Choi*, <span class="font-weight-bold">Sunghyun Park*</span>, Minsoo Lee*, and Jaegul Choo<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021, Virtual, Accepted (27% acceptance rate).</i><br>
                                <a href="https://arxiv.org/abs/2103.16874">[Paper]</a>
                                <a href="https://psh01087.github.io/VITON-HD/">[Project]</a>
                                <a href="https://github.com/shadow2496/VITON-HD">[Code & Dataset]</a>
                                <a href="https://www.slideshare.net/ssusere1762e/cvpr-2021-vitonhd-highresolution-virtual-tryon-via-misalignmentaware-normalization">[PPT]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Vid-ODE -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/vid-ode.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation</span><br>
                                <span class="font-weight-bold">Sunghyun Park*</span>, Kangyeol Kim*, Junsoo Lee, Jaegul Choo, Joonseok Lee, Sookyung Kim, and Edward Choi<br>
				                <i>AAAI Conference on Artificial Intelligence (AAAI), 2021, Virtual, Accepted (21% acceptance rate).</i><br>
                                <i style="color:red;">Qualcomm Innovation Fellowship Korea 2021.</i><br>
                                <a href="https://arxiv.org/abs/2010.08188">[Paper]</a>
                                <a href="https://psh01087.github.io/Vid-ODE/">[Project]</a>
                                <a href="https://github.com/psh01087/Vid-ODE">[Code & Dataset]</a>
                                <a href="https://www.slideshare.net/ssusere1762e/vidode-aaai-2021">[PPT]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Hurricane Nowcasting -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/nowcasting.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Hurricane Nowcasting with Irregular Time-step using Neural-ODE and Video Prediction</span><br>
                                <span class="font-weight-bold">Sunghyun Park*</span>, Kangyeol Kim*, Sookyung Kim*, Joonseok Lee, Junsoo Lee, Jiwoo Lee, and Jaegul Choo<br>
                                <i>International Conference on Learning Representations Workshop (ICLRW), 2020, Accepted as Spotlight Presentation.</i><br>
                                <a href="https://www.climatechange.ai/papers/iclr2020/21/paper.pdf">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- PP-VTON -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/pp-vton.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">PP-VTON: Pose-Preserving Image-based Virtual Try-On Network</span><br>
                                <span class="font-weight-bold">Sunghyun Park*</span> and Seunghwan Choi*<br>
                                <i>Korea Software Congress (KSC), 2019, Pyeongchang, Korea, Accepted.</i><br>
                                <a href="http://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE09301689">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Focus and Track -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/focus_and_track.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Learning to Focus and Track Extreme Climate Events</span><br>
                                Sookyung Kim*, <span class="font-weight-bold">Sunghyun Park*</span>, Sunghyo Chung*, Joonseok Lee, Yunsung Lee, Hyojin Kim, Mr Prabhat, and Jaegul Choo<br>
                                <i>British Machine Vision Conference (BMVC), 2019, Cardiff, UK, Accepted as Spotlight Presentation (6.9% acceptance rate for spotlight papers).</i><br>
                                <i>ICML 2019 Workshop Climate Change, 2019, California, USA, Accepted.</i><br>
                                <i>NIPS 2019 Workshop Tackling Climate Change, 2019, Vancouver, Canada, Accepted.</i><br>
                                <a href="https://bmvc2019.org/wp-content/uploads/papers/0728-paper.pdf">[Paper]</a>
                            </p>
                        </div>
                    </div>
                </div>
                <hr>
                <div>
                    <h3 class="subtitle">Under Review</h3>
                    <!-- Long-tailed OCR -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/long_tail_ocr.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Improving Scene Text Recognition for Character-Level Long-Tailed Distribution</span><br>
                                <span class="font-weight-bold">Sunghyun Park*</span>, Sunghyo Chung*, Jungsoo Lee, and Jaegul Choo<br>
                                <i>Under Review</i><br>
                                <a href="https://arxiv.org/abs/2304.08592">[Paper]</a>
                                <a href="https://github.com/psh01087/Long-Tailed-STR">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <!-- RobustSwap -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/robustswap.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">RobustSwap: A Simple yet Robust Face Swapping Model against Attribute Leakage</span><br>
                                Jaeseong Lee*, Taewoo Kim*, <span class="font-weight-bold">Sunghyun Park</span>, Younggun Lee, and Jaegul Choo<br>
                                <i>Under Review</i><br>
                                <a href="https://arxiv.org/abs/2303.15768">[Paper]</a>
                                <a href="https://robustswap.github.io/">[Project]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Balanced Learning for Speaker Recognition -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/placeholder.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Balanced Learning for Multi-Domain Long-tailed Speaker Recognition</span><br>
                                Janghoon Cho*, <span class="font-weight-bold">Sunghyun Park*</span>, Hyunsin Park, Hyoungwoo Park, Seunghan Yang, and Sungrack Yun<br>
                                <i>Under Review</i><br>
                                <a href="">[Paper]</a>
                            </p>
                        </div>
                    </div>
                    <!-- Expression Domain Translation Network for Cross-domain Head Reenactment -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/edtn.jpg" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">Expression Domain Translation Network for Cross-domain Head Reenactment</span><br>
                                Taewoong Kang*, Jeongsik Oh*, Jaeseong Lee, <span class="font-weight-bold">Sunghyun Park</span>, and Jaegul Choo<br>
                                <i>Under Review</i><br>
                                <a href="https://arxiv.org/abs/2310.10073">[Paper]</a>
                                <a href="https://keh0t0.github.io/research/EDTN/">[Project]</a>
                                <a href="https://github.com/kangyeolk/AnimeCeleb/tree/main/EDTN">[Code]</a>
                            </p>
                        </div>
                    </div>
                    <!-- StableVITON -->
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./images/stableviton.png" alt="" class="figure-img img-fluid" style="margin:10px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <p class="lead">
                                <span class="font-weight-bold">StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On</span><br>
                                Jeongho Kim, Gyojung Gu, Minho Park, <span class="font-weight-bold">Sunghyun Park</span>, and Jaegul Choo<br>
                                <i>Under Review</i><br>
                                <a href="https://arxiv.org/abs/2312.01725">[Paper]</a>
                                <a href="https://rlawjdghek.github.io/StableVITON/">[Project]</a>
                                <a href="https://github.com/rlawjdghek/StableVITON">[Code]</a>
                            </p>
                        </div>
                    </div>
                </div>
                <hr>
                <!-- Work Experience -->
                <div>
                    <h3 class="subtitle">Work Experience</h3>
                    <p class="lead">
                        <span class="font-weight-bold">[Aug. 2022 - Aug. 2023] </span> Qualcomm AI Research, Research Intern (Morpheus Team)</br>
                        <span class="font-weight-bold">[Jul. 2021 - Dec. 2021] </span> Kakao Enterprise, Membership Program (OCR Team)</br>
                        <span class="font-weight-bold">[Mar. 2021 - Jun. 2021] </span> Kakao Enterprise, Research Intern (OCR Team)</br>
                        <span class="font-weight-bold">[Jul. 2018 - Aug. 2019] </span> DAVIAN, Korea University, Undergraduate Researcher (Advised by Prof. <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>)</br>
                        <span class="font-weight-bold">[Jan. 2018 - Feb. 2018] </span> Daumsoft, Intern</br>
                    </p>
                </div>
                <hr>
                <!-- Conference Reviewers -->
                <div>
                    <h3 class="subtitle">Professional Services</h3>
                    <p class="lead">
                        <span class="font-weight-bold">Conference Reviewers:</span> CVPR, ECCV, ICCV, NeurIPS, EuroGraphics, ICIP
                        <!-- IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR): 2022, 2023</br>
                        European Conference on Computer Vision (ECCV): 2022</br>
                        International Conference on Computer Vision (ICCV): 2023</br>
                        Advances in Neural Information Processing Systems (NeurIPS): 2023</br>
                        IEEE International Conference on Image Processing (ICIP): 2022</br>
                        European Association for Computer Graphics (EuroGraphics): 2022</br> -->
                    </p>
                </div>
                

                <!-- Teaching Experience -->
                <!-- <div>
                    <h3 class="subtitle">Teaching Experience</h3>
                    <h6>- AI Workshop Instructor</h6>
                    <p class="lead">
                        <span class="font-weight-bold">[Sep. 2021 - Oct. 2021]</span> SAIT: Machine Learning / Deep Learning, Computer Vision</br>
                        <span class="font-weight-bold">[Sep. 2021]</span> SK Telecom: Big Tech Academy, AI Course, Computer Vision</br>
                        <span class="font-weight-bold">[Dec. 2020 - Feb. 2021]</span> Global Startup Academy: Computer Vision & Kaggle Competition</br>
                        <span class="font-weight-bold">[Oct. 2020]</span> Samsung DS KAIST: AI Expert Program, Image-to-Image Translation</br>
                        <span class="font-weight-bold">[Sep. 2020]</span> SK Telecom: Image Generation</br>
                        <span class="font-weight-bold">[Oct. 2019]</span> Samsung DS KAIST: AI Expert Program, NLP</br>
                        <span class="font-weight-bold">[Aug. 2019]</span> Samsung DS KAIST: AI Expert Program, Computer Vision</br>
                    </p>
                    <h6>- Teaching Assistant</h6>
                    <p class="lead">
                        <span class="font-weight-bold">[Sep. 2021 - Dec. 2021]</span> Deep Learning for Computer Vision, KAIST (AI604)</br>
                        <span class="font-weight-bold">[Sep. 2020 - Dec. 2020]</span> Deep Learning for Computer Vision, KAIST (AI604)</br>
                        <span class="font-weight-bold">[Mar. 2020 - Jun. 2020]</span> Advanced Deep Learning, KAIST (AI602)</br>
                    </p>

                </div>
                <hr> -->
            </div>
            <div class="col-md-2"></div>
        </div>
    </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body></html>
