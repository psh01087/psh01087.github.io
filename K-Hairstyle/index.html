<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title>K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification</title>
    <style type="text/css">
    .center {
        text-align: center;
    }

    .lead {
        font-size: 1.0rem;
        font-family: Georgia, "Times New Roman", Times, serif;
    }

    .author {
        font-size: 1.1rem;
    }

    .figure-caption {
        color: #6c757d;
    }
    </style>
</head>

<body>
    <div class="container" style="margin-top:20px;">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-9">
                <center>
                    <h2 style="margin: 20px;">K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification</h2>
                    <h4>ICIP 2021</h4>
                    <!-- author -->
                    <div class="row author">
                        <div class="col-sm-3">
                            <a href="">Taewoo Kim*</a>
                            <br>
                            KAIST
                        </div>
                        <div class="col-sm-3">
                            <a href="">Chaeyeon Chung*</a>
                            <br>
                            KAIST
                        </div>
                        <div class="col-sm-3">
                            <a href="https://psh01087.github.io/">Sunghyun Park*</a>
                            <br>
                            KAIST
                        </div>
                        <div class="col-sm-3">
                            <a href="">Gyojung Gu</a>
                            <br>
                            Nestyle
                        </div>
                    </div>
                    <div class="row author" style="margin-top:18px;">
                        <div class="col-sm-3">
                            <a href="">Keonmin Nam</a>
                            <br>
                            Nestyle
                        </div>
                        <div class="col-sm-3">
                            <a href="">Wonzo Choe</a>
                            <br>
                            Smilegate AI
                        </div>
                        <div class="col-sm-3">
                            <a href="">Jaesung Lee</a>
                            <br>
                            Aiinplanet
                        </div>
                        <div class="col-sm-3">
                            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
                            <br>
                            KAIST
                        </div>
                    </div>
                </center>
                <hr>
                <div>
                    <center>
                    <figure class="figure">
                        <img src="./figs/teaser_image.png" class="figure-img img-fluid" alt="Responsive image" style="margin:20px 0px;">
                    </figure>                
                    </center>
                </div>
                <!-- Abstract -->
                <div>
                    <h3>Abstract</h3>
                    <p class="text-justify">
                        The hair and beauty industry is a fast-growing industry.
                        This led to the development of various applications, such as virtual hair dyeing or hairstyle translations, to satisfy the customer needs.
                        Although several hairstyle datasets are available for these applications, they often consist of a relatively small number of images with low resolution, thus limiting their performance on high-quality hair editing.
                        In response, we introduce a novel large-scale Korean hairstyle dataset, Khairstyle, containing 500,000 high-resolution images.
                        In addition, K-hairstyle includes various hair attributes annotated by Korean expert hairstylists as well as hair segmentation masks.
                        We validate the effectiveness of our dataset via several applications, such as hair dyeing, hairstyle translation, and hairstyle classification.
                    </p>
                </div>
                <hr>
                <!-- Overview -->
                <div>
                    <h3>Overview</h3>
                    <p class="text-justify">
                        K-hairstyle provides 500,000 high-resolution images with a rich set of annotations, such as hairstyle classes, hair segmentation masks, and various attributes.
                        <ul>
                            <li><b>High-resolution image.</b> The images with a maximum resolution of 4032×3024 are collected using high-end cameras.</li>
                            <li><b>Large-scale dataset.</b> We provide 500,000 images, more than any other existing hairstyle datasets.</li>
                            <li><b>Multi-view image.</b> The dataset contains multi-view images that are captured from various camera angles for each person. The angles include 2 different vertical camera angles and about 10 to 60 different horizontal angles.</li>
                            <li><b>Segmentation mask.</b> The hair regions of images are manually labeled in the form of a polygon. The blurred face regions are also labeled in the same way.</li>
                            <li><b>Hairstyle attributes.</b> Various hairstyle-related attributes are annotated by Korean expert hairstylists. In detail, different hairstyles are categorized into 31 types, and 63 additional attributes, such as hair color, length, and curl, are also labeled.</li>
                            <li><b>Blurred face.</b> Due to the privacy issue, we made the facial region blurry.</li>
                        </ul>
                    </p>
                </div>
                <!-- Annotations -->
                <div>
                    <h3>Annotations</h3>
                    <p class="text-justify">
                        K-hairstyle includes 11 hairstyle-related annotations and 9 additional annotations including segmentation masks.                        
                        The details of 11 hairstyle-related annotations are as follows:
                        <ul>
                            <li><b>Basestyle</b>: type of hairstyles, categorical data.</li>
                            <li><b>Basestyle_type</b>: type of hair length, categorical data.</li>
                            <li><b>Length</b>: detailed type of hair length, categorical data.</li>
                            <li><b>Curl</b>: type of curl, categorical data.</li>
                            <li><b>Bang</b>: type of bangs, categorical data.</li>
                            <li><b>Loss</b>: degree of hair loss, categorical data.</li>
                            <li><b>Side</b>: type of side hair, categorical data.</li>
                            <li><b>Color</b>: type of hair color, categorical data.</li>
                            <li><b>Exceptional</b>: type of exceptional hairstyle, categorical data.</li>
                            <li><b>Rgb</b>: mean rgb value of hair region based on its hair segmentation mask, 3-dim array of float.</li>
                            <li><b>Before-after</b>: whether a photo is taken before styling or after styling, categorical data.</li>
                        </ul>
                    
                        The details of 12 additional annotations including segmentation masks are as follows:
                        <ul>
                            <li><b>Id</b>: unique id for each image, categorical data.</li>
                            <li><b>Path</b>: path of an image, string data.</li>
                            <li><b>Source</b>: identity of an image (not unique for each image since we have multiple images for each identity), categorical data.</li>
                            <li><b>Age</b>: age of a person in an image, int data.</li>
                            <li><b>Gender</b>: gender of a person in an image, categorical data.</li>
                            <li><b>Height</b>: image height, int data.</li>
                            <li><b>Width</b>: image width, int data.</li>
                            <li><b>Front</b>: whether the image is facing the front, boolean data.</li>
                            <li><b>Horizontal</b>: horizontal camera angle which ranges from 0 (the front) to 360, int data.</li>
                            <li><b>Vertical</b>: vertical camera angle, categorical data.</li>
                            <li><b>Hair mask</b>: polygon coordinates of hair segmentation mask, string data.</li>
                            <li><b>Face mask</b>: polygon coordinates of blurred face segmentation mask, string data.</li>                            
                        </ul>
                    
                        The examples of multi-view image are as follows:
                        <center>
                        <figure class="figure">
                            <img src="./figs/multi-view.png" class="figure-img img-fluid" alt="Responsive image" style="margin:20px 0px;">
                        </figure>                
                        </center>
                    </p>
                </div>
                <!-- Downloads -->
                <div>
                    <h3>Downloads (220618 updated)</h3>
                    <p class="text-justify">
                        We provide <b>mqset</b>, <b>hqset</b>, and <b>rawset</b> each of which contains 512x512, 1024x1024, and 4032×3024 images, respectively.
                        In case of <b>mqset</b> and <b>hqset</b>, the images are cropped, including its entire hair.
                        Note that the provided annotation files are for <b>mqset</b>.
                        The annotations for <b>hqset</b> and <b>rawset</b> can be obtained using the file name in <b>path</b> attribute.
                        For instance, if there is 'ABC1234.jpg' in <b>hqset</b> or <b>rawset</b>, the data instance whose <b>path</b> contains 'ABC1234.jpg' can be matched to the image.
                        The annotations are split into two files, <b>annotations.pkl</b> and <b>annotations_mask.pkl</b>.
                        <b>annotations.pkl</b> includes hairstyle-related annotations and additional annotations except segmentation masks.
                        <b>annotations_mask.pkl</b> contains segmentation masks of hair and blurred face in the form of polygon coordinates.
                        Both the image files and the annotation files can be downloaded via the links below.
                        <ul>
                            <li><b>Training</b>: <a href="https://davian-lab.quickconnect.to/d/s/p9A5kbK4danKU4WeoqSMiudPFX7Qmiau/6cgl793b8R2Pp6u4rPT-NtuwmLfYI5Vi-_7SAyvXimwk">[mqset]</a> <a href="https://davian-lab.quickconnect.to/d/s/p9AVf0sKXczzq8YrDUCh4d0LxO8Av0PC/ckm7D6Dqm3xn56PT0szjEDaQqMbPtdop-8bIgNcTimwk">[hqset]</a> <a href="https://davian-lab.quickconnect.to/d/s/p9A6AZu4nvwmc5R3LZ0qz8dmheCtPrc3/C0mub_CFpZsu2jGatNDxPAmoHDKltYLM-GLSgquXimwk">[rawset]</a></li>  
                            <li><b>Validation</b>: <a href="https://davian-lab.quickconnect.to/d/s/p9B00klYuWYhBeWDVeUFF4wRbrKeOjM5/i3gjyLgJLSD8EijSHy8LieSn4ahmK-hl-YrYA4Bvjmwk">[mqset]</a> <a href="https://davian-lab.quickconnect.to/d/s/p9B00femZ2XhVmBYjk3GMT45NUZJwLAg/4AOA9MkcNjsKkYgLF4IHpTPpcUP-IY6R--bWAsRDjmwk">[hqset]</a> <a href="https://davian-lab.quickconnect.to/d/s/p9B00oskIlK77WtNWJZ0wQ5W0d2qSRcs/4EUN4qujmV6K64kw99HNyBljokmjXgal-3bagQijjmwk">[rawset]</a></li> 
                        </ul>
                    </p>
                    <!-- <div class="col-sm-2">
                        <a href=""><img src="./figs/download_icon.png" class="figure-img img-fluid" alt="" style="margin:20px;"></a>
                    </div> -->
                </div>
                <hr>
                <div>
                    <h3>Paper and Supplementary Material</h3>
                    <div class="row">
                        <div class="col-sm-3">
                            <img src="./figs/paper.png" class="img-fluid border" alt="" style="margin:20px;">
                        </div>
                        <div class="col" style="margin-top: auto; margin-bottom: auto;">
                            <div class="align-middle">
                                <a href="https://arxiv.org/abs/2102.06288">[Paper]</a>
                                <p class="lead">
                                    ICIP 2021. <br>
                                    Taewoo Kim*, Chaeyeon Chung*, Sunghyun Park*, Gyojung Gu, Keonmin Nam, Wonzo Choe, Jaesung Lee, Jaegul Choo. <br>
                                    "K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification"
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="col-md-2"></div>
    </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>

</html>
